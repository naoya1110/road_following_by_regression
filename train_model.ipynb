{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naoya1110/road_following_by_regression/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XDPz7h7mBs4"
      },
      "source": [
        "# Road Following by Regression - Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2QUA6Rawrek"
      },
      "source": [
        "## Introduction\n",
        "Once you have finished data collection for you road following task, you need to train a model with your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r5NfcQO3Ypa"
      },
      "source": [
        "### GPU\n",
        "Please make sure we can use a GPU for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0BLwskStrUB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKQAYqgs2UI_"
      },
      "source": [
        "### Basic Python Packages\n",
        "Let's import basic Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH57yMgb2VEh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "import glob\n",
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPpYl8py2CJz"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8PoOJaVmBs-"
      },
      "source": [
        "### Upload & Extract Dataset\n",
        "\n",
        "We need to upload the `dataset_reg.zip` file in the file browser of the Google Colab. This takes time depending the size of your dataset. After uploading is finished, you can extract it with the next command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIjqaJK6mBs_"
      },
      "outputs": [],
      "source": [
        "! unzip -q dataset_reg.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4StH_vdmBs_"
      },
      "source": [
        "Now we should see a directory named ``dataset_reg`` in the file browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNe8qgKuxoQ7"
      },
      "source": [
        "#### *If your `dataset_reg.zip` file is in your google drive*\n",
        "\n",
        "First you need to mount your google drive with the next command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g9GyxvLk_FY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfGGKRB2xyV4"
      },
      "source": [
        "Then extract the `dataset_reg.zip` file. Remenber to change the file path appropriate for your `dataset_reg.zip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_nrfm_PlNtO"
      },
      "outputs": [],
      "source": [
        "!unzip -q /path/to/your/dataset_reg.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MN9UVYCz3nR"
      },
      "source": [
        "### Remove Broken Data\n",
        "The dataset directory may contain some broken image data or unnecessary directories for some reasons. Such data will cause errors when we train the model. So it is better to remove those data before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piJmvrfI1Dgh"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"dataset_reg\"\n",
        "filenames = sorted(os.listdir(dataset_dir))\n",
        "\n",
        "for filename in filenames:\n",
        "    path = os.path.join(dataset_dir, filename)\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        try:\n",
        "            os.remove(path)\n",
        "            print(\"Removed\", path)\n",
        "        except IsADirectoryError:\n",
        "            shutil.rmtree(path)\n",
        "            print(\"Removed\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCwm8-zBmBtA"
      },
      "source": [
        "### Create Dataset\n",
        "Now we use the ``ImageFolder`` dataset class available with the ``torchvision.datasets`` package.  We attach transforms from the ``torchvision.transforms`` package to prepare the data for training.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdZgOq1S18y5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def get_x(path, width):\n",
        "    \"\"\"Gets the x value from the image filename\"\"\"\n",
        "    return float(int(path.split(\"_\")[3])) / width\n",
        "\n",
        "def get_y(path, height):\n",
        "    \"\"\"Gets the y value from the image filename\"\"\"\n",
        "    return float(int(path.split(\"_\")[4])) / height\n",
        "\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "class RegDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, directory):\n",
        "        self.directory = directory\n",
        "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
        "        self.color_jitter = transforms.ColorJitter(0.1, 0.1, 0.1, 0.1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        \n",
        "        image = PIL.Image.open(image_path)\n",
        "        width, height = image.size\n",
        "        x = float(get_x(os.path.basename(image_path), width))\n",
        "        y = float(get_y(os.path.basename(image_path), height))\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "        image = transforms.functional.resize(image, (224, 224))\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        image = image.numpy()[::-1].copy()\n",
        "        image = torch.from_numpy(image)\n",
        "        image = transforms.functional.normalize(image, means, stds)\n",
        "        \n",
        "        return image, torch.tensor([x, y]).float()\n",
        "    \n",
        "dataset = RegDataset('dataset_reg')\n",
        "print(\"Number of data:\", len(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EGR3ex31iEH"
      },
      "source": [
        "### Data Distribution\n",
        "Let's visualize the distribution of x and y data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4jIMj5GB6RC"
      },
      "outputs": [],
      "source": [
        "x_list = []\n",
        "y_list = []\n",
        "for i in range(len(dataset)):\n",
        "    _, xy = dataset[i]\n",
        "    x_list.append(xy[0])\n",
        "    y_list.append(xy[1])\n",
        "\n",
        "sns.jointplot(np.array(x_list), np.array(y_list), xlim=(0, 1), ylim=(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woi0SNXZmBtB"
      },
      "source": [
        "### Train Test Split\n",
        "We need to split the dataset for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyxBiWhVmBtC"
      },
      "outputs": [],
      "source": [
        "test_size = 200\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - test_size, test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvgz5TAcmBtD"
      },
      "source": [
        "### Data Loaders\n",
        "Then we can make data loaders for the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zDsK187mBtD"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=50,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=50,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF8ZUfqtzIri"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEenc3DFmBtE"
      },
      "source": [
        "### Model Architecture\n",
        "We build a relatively simple CNN model but you can use any models you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z6lv7cVtgJw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64*7*7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),    # dropout layer\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)  \n",
        "        return x\n",
        "    \n",
        "model = Model().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiyURRAC3nt-"
      },
      "source": [
        "### torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhV2bhZztgHI"
      },
      "outputs": [],
      "source": [
        "! pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "for x_batch, _ in train_loader:\n",
        "    break\n",
        "\n",
        "input_shape = x_batch.shape\n",
        "print(input_shape)\n",
        "\n",
        "summary(model, input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqaeFfoOdJf7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYQgmwJPmBtF"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "Now we can train the model. Since this is a regresion model we are going to use `MSELoss()` as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzQx5mSnpt3y"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "\n",
        "loss_func = nn.MSELoss()                      # use MSE loss function.\n",
        "optimizer = optim.Adam(model.parameters(), lr=1E-4)    # set optimizer\n",
        "epochs = 30\n",
        "\n",
        "best_model_path = 'best_model_reg.pth'\n",
        "best_loss = 1E+9\n",
        "\n",
        "# create empty lists for saving metrics during training\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"-----------------------------\")\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # initialize metrics\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "\n",
        "    #--- Training Phase ---#\n",
        "    model.train()    # set model to training mode\n",
        "\n",
        "    pbar = tqdm(train_loader)\n",
        "    pbar.set_description(\"Train\")\n",
        "\n",
        "    for x_batch, y_batch in pbar:      # take mini batch data from train_loader\n",
        "        \n",
        "        x_batch = x_batch.to(device)     # load x_batch data on GPU\n",
        "        y_batch = y_batch.to(device)     # load y_batch data on GPU\n",
        "    \n",
        "        optimizer.zero_grad()                  # reset gradients to 0\n",
        "        p_batch = model(x_batch)               # do prediction\n",
        "        loss = loss_func(p_batch, y_batch)     # measure loss\n",
        "        loss.backward()                        # calculate gradients\n",
        "        optimizer.step()                       # update model parameters\n",
        "\n",
        "        train_loss += loss.item()                                # accumulate loss value\n",
        "\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "    #----------------------#\n",
        "\n",
        "    #--- Evaluation Phase ---#\n",
        "    with torch.no_grad():   # disable autograd for saving memory usage\n",
        "        model.eval()        # set model to evaluation mode\n",
        "\n",
        "        pbar = tqdm(test_loader)\n",
        "        pbar.set_description(\"Test\") \n",
        "\n",
        "        for x_batch, y_batch in pbar:   # take mini batch data from test_loader\n",
        "\n",
        "            x_batch = x_batch.to(device)     # load x_batch data on GPU\n",
        "            y_batch = y_batch.to(device)     # load y_batch data on GPU\n",
        "\n",
        "            p_batch = model(x_batch)              # do prediction\n",
        "            loss = loss_func(p_batch, y_batch)    # measure loss\n",
        "\n",
        "            test_loss += loss.item()                                # accumulate loss value\n",
        "            p_batch_label = torch.argmax(p_batch, dim=1)            # convert p_batch vector to p_batch_label\n",
        "\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "    #------------------------#\n",
        "\n",
        "    train_loss = train_loss/len(train_loader)                 # determine loss for training data\n",
        "    test_loss = test_loss/len(test_loader)                    # determine loss for test data \n",
        "\n",
        "    # show and store metrics\n",
        "    print(f\"Train Loss={train_loss:.5f}, Test Loss={test_loss:.5f}\")\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    test_loss_list.append(test_loss)\n",
        "\n",
        "    # save the model if test accuracy is better than before\n",
        "    if test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"Test loss decreased from {best_loss:.3f} to {test_loss:.3f}\")\n",
        "        print(f\"Model saved at {best_model_path}\")\n",
        "        best_loss = test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFRsHo9N34K7"
      },
      "source": [
        "### Learning Curves\n",
        "Let's check the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZlwSRJdtbyJ"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"font.size\"]=14\n",
        "real_epochs = np.arange(len(train_loss_list))+1\n",
        "\n",
        "plt.plot(real_epochs, train_loss_list, c=\"#1f77b4\", label=\"train loss\")\n",
        "plt.plot(real_epochs, test_loss_list, lw=0, marker=\"o\", c=\"#1f77b4\", label=\"test loss\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFYLCYrv4CB7"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbIQrLxheh5z"
      },
      "source": [
        "### Load The Best Model\n",
        "Let's load the best model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj8Ruep2tbjK"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(best_model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZosxM7YH4gD0"
      },
      "outputs": [],
      "source": [
        "truths = []\n",
        "preds = []\n",
        "\n",
        "with torch.no_grad():   # disable autograd for saving memory usage\n",
        "    model.eval()        # set model to evaluation mode\n",
        "\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)     # load x_batch data on GPU\n",
        "        p_batch = model(x_batch)    # predict\n",
        "\n",
        "        p_batch = p_batch.to(\"cpu\").numpy()\n",
        "        y_batch = y_batch.to(\"cpu\").numpy()\n",
        "        preds.append(p_batch)\n",
        "        truths.append(y_batch)\n",
        "\n",
        "preds = np.array(preds).reshape(test_size, 2)\n",
        "truths = np.array(truths).reshape(test_size, 2)\n",
        "\n",
        "plt.figure(figsize=(9, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([-1.2, 1.2], [-1.2, 1.2])\n",
        "plt.plot(truths[:,0], preds[:,0], lw=0, marker=\"o\")\n",
        "plt.grid()\n",
        "plt.xlim(-0.1, 1.1)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.xlabel(\"Ground Truth\")\n",
        "plt.ylabel(\"Prediction\")\n",
        "plt.title(\"x position\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([-1.2, 1.2], [-1.2, 1.2])\n",
        "plt.plot(truths[:,1], preds[:,1], lw=0, marker=\"o\")\n",
        "plt.grid()\n",
        "plt.xlim(-0.1, 1.1)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.xlabel(\"Ground Truth\")\n",
        "plt.title(\"y position\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSmr3eXie0hq"
      },
      "source": [
        "### Predictions for Test Data\n",
        "Let's see the predictions for the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7jCGoOKywy6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "\n",
        "for i in range(50):\n",
        "    image, xy = test_dataset[i]\n",
        "    image = np.transpose(image, (1,2,0))\n",
        "    \n",
        "    image[:, :, 0] = image[:, :, 0]*stds[0]+means[0]\n",
        "    image[:, :, 1] = image[:, :, 1]*stds[1]+means[1]\n",
        "    image[:, :, 2] = image[:, :, 2]*stds[2]+means[2]\n",
        "    image = (255*image).numpy().astype(\"uint8\")\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    xy_truth = tuple((truths[i]*224).astype(\"int\"))\n",
        "    xy_pred = tuple((preds[i]*224).astype(\"int\"))\n",
        "\n",
        "    plt.subplot(5, 10, i+1)\n",
        "    image = cv2.circle(image, xy_truth, 8, (0,255, 0), 3)\n",
        "    image = cv2.circle(image, xy_pred, 8, (255, 0, 255), 3)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVJk_B4GmBtG"
      },
      "source": [
        "## Download Model\n",
        "Once you finished training, download `best_model_reg.pth` from the file browser and upload it to your JetBot."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}