{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKwvuMxsFghR"
   },
   "source": [
    "# Road Following by Regression - Live Demo\n",
    "\n",
    "In this notebook, we will try to make the JetBot to follow the desired road by using the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Ae369MGcZP"
   },
   "source": [
    "## Model Architecture\n",
    "First we define a DNN model. This needs to be identical to what used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wJFwgmW3FghW",
    "outputId": "2c810d06-2a6e-4f4a-d935-3e23529b2d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),    # dropout layer\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)  \n",
    "        return x\n",
    "    \n",
    "model = Model().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjJCDzvGFghX"
   },
   "source": [
    "## Load The Best Model\n",
    "Next we need to upload the `best_model_reg.pth` in the file browser. Then load the parameters on the model from the `best_model_reg.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3kYGMn_ZFghX",
    "outputId": "7370ecc2-c793-4ea5-9ad8-33e69798ac44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_reg.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRGQRpcBFghY"
   },
   "source": [
    "## Preprocessing Function\n",
    "\n",
    "Now we create a function for preprocessing image data taken by the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eTaXtdgTFghY"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1k2V5NKkHkAm"
   },
   "source": [
    "## Camera Instance\n",
    "Now we create a camera instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EdgXKPloFgha"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce94e50453e46b082896dc63e93c6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "size = 224\n",
    "image = widgets.Image(format='jpeg', width=size, height=size)\n",
    "camera = Camera.instance(width=size, height=size)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StFLmt8uFghc"
   },
   "source": [
    "## Robot Instance\n",
    "Create the robot instance to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bCsq9LspFghc"
   },
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "robot.set_motors(-0.1, 0.1)\n",
    "time.sleep(0.1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define move_robot function\n",
    "Define a function to control the motors depending on the x and y coordinates of the target point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_robot(x, y):\n",
    "    # move robot\n",
    "    speed_gain = 0.3\n",
    "    b = 0.3               # kind of steering gain\n",
    "    x = x/size-0.5\n",
    "    y = 1-y/size\n",
    "    a = np.sqrt(x**2 + y**2)\n",
    "    angle = np.pi/2-np.arctan2(y, x)+1E-6\n",
    "    c = a/np.sin(np.abs(angle))\n",
    "\n",
    "    if angle >= 0:\n",
    "        left_motor = speed_gain*(c+b)*np.abs(angle)\n",
    "        right_motor = speed_gain*(c-b)*np.abs(angle)  \n",
    "    else:\n",
    "        left_motor = speed_gain*(c-b)*np.abs(np.abs(angle))\n",
    "        right_motor = speed_gain*(c+b)*np.abs(np.abs(angle))\n",
    "\n",
    "    robot.set_motors(left_motor, right_motor)\n",
    "    \n",
    "    return left_motor, right_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Let's try to make an inference. This process takes for a while for the first time because it needs to load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    img = camera.value\n",
    "    img = preprocess(img)\n",
    "    xy = size*model(img)[0].to(\"cpu\").numpy()\n",
    "    x = int(xy[0])\n",
    "    y = int(xy[1])\n",
    "    left_motor, right_motor = move_robot(x, y)\n",
    "    time.sleep(0.1)\n",
    "    robot.stop()\n",
    "    print(f\"left_motor={left_motor}, right_motor={right_motor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uILzSjgmKEXg"
   },
   "source": [
    "## Run JetBot\n",
    "Run JetBot with a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kLBthwAFghc",
    "outputId": "863df5c6-2f49-42ab-e48a-bcba8f0ba838"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "display(image)\n",
    "steps = 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(steps):\n",
    "        try:\n",
    "            img = camera.value\n",
    "            img = preprocess(img)\n",
    "\n",
    "            xy = size*model(img)[0].to(\"cpu\").numpy()f\n",
    "            x = int(xy[0])\n",
    "            y = int(xy[1])\n",
    "\n",
    "            left_motor, right_motor = move_robot(x, y)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        now = time.time()\n",
    "        dt = now-t0\n",
    "        t0 = now\n",
    "        FPS = 1/dt\n",
    "\n",
    "        print(f\"\\rStep:{i+1}/{steps}, left_motor={left_motor:.3f}, right_motor={right_motor:.3f}, FPS:{FPS:.1f}\", end=\"\")\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop robot & camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHUWbWd3I6c2"
   },
   "source": [
    "If you are done, stop the robot and the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6HPA2wWFghc"
   },
   "outputs": [],
   "source": [
    "robot.stop()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "live_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
