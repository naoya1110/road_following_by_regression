{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKwvuMxsFghR"
   },
   "source": [
    "# Road Following by Regression - Live Demo TensorRT\n",
    "\n",
    "In this notebook, we drive the JetBot with the ResNet18 TensorRT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjJCDzvGFghX"
   },
   "source": [
    "## Load ResNet18 TensorRT model\n",
    "First we load the ResNet18 TensorRT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_model_reg_resnet18_trt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRGQRpcBFghY"
   },
   "source": [
    "## Preprocessing Function\n",
    "\n",
    "Now we create a function for preprocessing image data taken by the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eTaXtdgTFghY"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.cuda().half()\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1k2V5NKkHkAm"
   },
   "source": [
    "## Camera Instance\n",
    "Now we create a camera instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EdgXKPloFgha"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb191df523b497399e01f875550bcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "size = 224\n",
    "image = widgets.Image(format='jpeg', width=size, height=size)\n",
    "camera = Camera.instance(width=size, height=size)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StFLmt8uFghc"
   },
   "source": [
    "## Robot Instance\n",
    "Create the robot instance to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bCsq9LspFghc"
   },
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "robot.set_motors(-0.1, 0.1)\n",
    "time.sleep(0.1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define move_robot function\n",
    "Define a function to control the motors depending on the x and y coordinates of the target point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_robot(x, y):\n",
    "    # move robot\n",
    "    speed_gain = 0.3\n",
    "    b = 0.3               # kind of steering gain\n",
    "    x = x/size-0.5\n",
    "    y = 1-y/size\n",
    "    a = np.sqrt(x**2 + y**2)\n",
    "    angle = np.pi/2-np.arctan2(y, x)+1E-6\n",
    "    c = 0.5*a/np.sin(np.abs(angle))\n",
    "\n",
    "    if angle >= 0:\n",
    "        left_motor = speed_gain*(c+b)*np.abs(2*angle)\n",
    "        right_motor = speed_gain*(c-b)*np.abs(2*angle)  \n",
    "    else:\n",
    "        left_motor = speed_gain*(c-b)*np.abs(np.abs(2*angle))\n",
    "        right_motor = speed_gain*(c+b)*np.abs(np.abs(2*angle))\n",
    "    \n",
    "    left_motor = max(0, left_motor)\n",
    "    right_motor = max(0, right_motor)\n",
    "\n",
    "    robot.set_motors(left_motor, right_motor)\n",
    "    \n",
    "    return left_motor, right_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Let's try to make an inference. This process takes for a while for the first time because it needs to load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "[128.2 139.9]\n",
      "left_motor=0.15000024812928872, right_motor=0.08301894435564738\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    img = camera.value\n",
    "    img = preprocess(img)\n",
    "    print(img.shape)\n",
    "    xy = size*model_trt(img)[0].to(\"cpu\").numpy()\n",
    "    print(xy)\n",
    "    x = int(xy[0])\n",
    "    y = int(xy[1])\n",
    "    left_motor, right_motor = move_robot(x, y)\n",
    "    time.sleep(0.1)\n",
    "    robot.stop()\n",
    "    print(f\"left_motor={left_motor}, right_motor={right_motor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uILzSjgmKEXg"
   },
   "source": [
    "## Run JetBot\n",
    "Run JetBot with a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9kLBthwAFghc",
    "outputId": "863df5c6-2f49-42ab-e48a-bcba8f0ba838"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb191df523b497399e01f875550bcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:500/500, left_motor=0.239, right_motor=0.083, FPS:17.3"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "display(image)\n",
    "steps = 500 # if you want to run JetBot longer, increase this value\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(steps):\n",
    "        try:\n",
    "            img = camera.value\n",
    "            img = preprocess(img)\n",
    "\n",
    "            xy = size*model_trt(img)[0].to(\"cpu\").numpy()\n",
    "            x = int(xy[0])\n",
    "            y = int(xy[1])\n",
    "\n",
    "            left_motor, right_motor = move_robot(x, y)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        now = time.time()\n",
    "        dt = now-t0\n",
    "        t0 = now\n",
    "        FPS = 1/dt\n",
    "\n",
    "        print(f\"\\rStep:{i+1}/{steps}, left_motor={left_motor:.3f}, right_motor={right_motor:.3f}, FPS:{FPS:.1f}\", end=\"\")\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Robot & Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHUWbWd3I6c2"
   },
   "source": [
    "If you are done, stop the robot and the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H6HPA2wWFghc"
   },
   "outputs": [],
   "source": [
    "robot.stop()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "live_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
